import geopandas as gpd
import numpy as np
from shapely.geometry import Point
from pathlib import Path
import warnings
import time

# User-defined parameters
BUFFER = 2000.0  # feet
TARGET_CRS = 'EPSG:6539'

# Relative file paths
SCRIPT_DIR = Path(__file__).parent
OUTPUT_DIR = SCRIPT_DIR / "output"
INPUT_DIR = SCRIPT_DIR / "input"
SITES_FILE = OUTPUT_DIR / "sites_flood.geojson"  # "sites"
HVI_DATA = INPUT_DIR / "HVI.geojson"             # "hvi"
FVI_DATA = INPUT_DIR / "FVI.geojson"             # "fvi"

OUTPUT_FILE = "sites_vul.geojson"

def ensure_crs_vector(gdf, target_crs):
    """Ensure the GeoDataFrame is in the target CRS, reproject if needed."""
    if gdf.crs is None:
        warnings.warn("Vector data has no CRS. Setting to target CRS.")
        gdf = gdf.set_crs(target_crs)
    elif gdf.crs.to_string() != target_crs:
        gdf = gdf.to_crs(target_crs)
    return gdf

def safe_float(val):
    """Convert value to float if possible, else return np.nan."""
    try:
        return float(val)
    except (ValueError, TypeError):
        return np.nan

def area_weighted_average(buffer_geom, overlay_gdf, value_field):
    """
    Compute area-weighted average of 'value_field' within 'overlay_gdf' polygons that overlap with 'buffer_geom'.
    Steps:
    - Clip or intersect overlay_gdf with buffer_geom
    - For each intersected polygon, calculate overlap area and weighted contribution
    - Compute sum of weighted values and sum of areas
    """
    # Intersect overlay with the buffer geometry
    clipped = gpd.overlay(overlay_gdf, gpd.GeoDataFrame(geometry=[buffer_geom], crs=overlay_gdf.crs), how='intersection')
    if clipped.empty:
        return np.nan
    
    # Compute area-weighted sum
    clipped['overlap_area'] = clipped.geometry.area
    # Convert value to float if not already
    clipped[value_field] = clipped[value_field].apply(safe_float)
    valid = clipped[~clipped[value_field].isna()]
    if valid.empty:
        return np.nan
    
    weighted_sum = (valid[value_field] * valid['overlap_area']).sum()
    area_sum = valid['overlap_area'].sum()
    if area_sum == 0:
        return np.nan
    return weighted_sum / area_sum

def main():
    start_time = time.time()

    # Load datasets
    if not SITES_FILE.exists():
        raise FileNotFoundError(f"Sites file not found: {SITES_FILE}")
    if not HVI_DATA.exists():
        raise FileNotFoundError(f"HVI data not found: {HVI_DATA}")
    if not FVI_DATA.exists():
        raise FileNotFoundError(f"FVI data not found: {FVI_DATA}")

    sites = gpd.read_file(SITES_FILE)
    hvi = gpd.read_file(HVI_DATA)
    fvi = gpd.read_file(FVI_DATA)

    # Ensure all in TARGET_CRS
    sites = ensure_crs_vector(sites, TARGET_CRS)
    hvi = ensure_crs_vector(hvi, TARGET_CRS)
    fvi = ensure_crs_vector(fvi, TARGET_CRS)

    # Prepare output columns
    for col in ['hvi_area', 'ssvul_area', 'tivul_area']:
        if col not in sites.columns:
            sites[col] = np.nan

    # Process each site
    # For performance, consider using spatial indexes (sindex) on hvi and fvi if large datasets.
    # For simplicity, we'll directly compute intersections.
    # Optional: build spatial indexes
    hvi_sindex = hvi.sindex
    fvi_sindex = fvi.sindex

    for idx, site in sites.iterrows():
        geom = site.geometry
        if geom is None or geom.is_empty:
            continue
        
        # Create buffer from centroid
        centroid = geom.centroid
        buffer_geom = centroid.buffer(BUFFER)

        # Area-weighted average for HVI
        # First, limit to hvi polygons that intersect buffer
        possible_hvi = hvi.iloc[list(hvi_sindex.intersection(buffer_geom.bounds))]
        hvi_area_val = area_weighted_average(buffer_geom, possible_hvi, 'HVI')

        # Area-weighted averages for FVI (ss_80s, tid_80s)
        possible_fvi = fvi.iloc[list(fvi_sindex.intersection(buffer_geom.bounds))]
        ss80_area_val = area_weighted_average(buffer_geom, possible_fvi, 'ss_80s')
        tid80_area_val = area_weighted_average(buffer_geom, possible_fvi, 'tid_80s')

        # Store results
        sites.at[idx, 'hvi_area'] = hvi_area_val
        sites.at[idx, 'ssvul_area'] = ss80_area_val
        sites.at[idx, 'tivul_area'] = tid80_area_val

    # Save results
    out_path = OUTPUT_DIR / OUTPUT_FILE
    sites.to_file(out_path, driver='GeoJSON')
    print(f"Results saved to {out_path}")

    elapsed = time.time() - start_time
    print(f"Vulnerability analysis completed in {elapsed:.2f} seconds ({elapsed/60:.2f} minutes).")

if __name__ == "__main__":
    main()